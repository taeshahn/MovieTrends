{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 네이버 영화 크롤링 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_review_info(movie_nm):\n",
    "    review_url, num_pages = None, 0\n",
    "    search_url = \"https://movie.naver.com/movie/search/result.nhn?query=\" + movie_nm + \"&section=all&ie=utf8\"\n",
    "    search_resp = requests.get(search_url)\n",
    "    search_html = BeautifulSoup(search_resp.content, 'html.parser')\n",
    "    if search_html.find('ul', {'class': 'search_list_1'}) is not None: # 해당 영화 검색 결과가 존재하는 경우\n",
    "        a_tag = search_html.find('ul', {'class': 'search_list_1'}).find('a')\n",
    "        re_movie = re.compile('code=[0-9]{1,6}')\n",
    "        movie_code = re.sub('code=', '', re_movie.findall(str(a_tag))[0])\n",
    "        review_url = \"https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=\" + movie_code\n",
    "        review_html = BeautifulSoup(requests.get(review_url).content, 'html.parser')\n",
    "        review_score = review_html.find('div', {'class': 'score_total'})\n",
    "        if review_score is not None: # 해당 영화 리뷰 페이지가 존재하는 경우 (국내개봉작)\n",
    "            review_count = int(review_score.find('strong').findChildren('em')[-1].getText().replace(',', ''))\n",
    "            num_pages = int(math.ceil(review_count/10))\n",
    "    return(review_url, num_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_review_subset(movie_nm, url):\n",
    "    resp = requests.get(url)\n",
    "    html = BeautifulSoup(resp.content, 'html.parser')\n",
    "    score_result = html.find('div', {'class': 'score_result'})\n",
    "    lis = score_result.findAll('li')\n",
    "    lis_df = pd.DataFrame()\n",
    "    for li in lis:\n",
    "        nickname = li.findAll('a')[0].find('span').getText() if li.findAll('a')[0].find('span') is not None else None\n",
    "        created_at = datetime.strptime(li.find('dt').findAll('em')[-1].getText(), \"%Y.%m.%d %H:%M\")\n",
    "        review_text = li.find('p').getText().translate(str.maketrans({\"\\n\": \"\", \"\\r\": \"\", \"\\t\": \"\"}))\n",
    "        score = li.find('em').getText()\n",
    "        btn_likes = li.find('div', {'class': 'btn_area'}).findAll('strong')\n",
    "        like = btn_likes[0].getText()\n",
    "        dislike = btn_likes[1].getText()\n",
    "        watch_movie = li.find('span', {'class':'ico_viewer'})\n",
    "        \n",
    "        li_df = pd.DataFrame({\"movie_nm\": [movie_nm],\n",
    "                              \"nickname\": [nickname],\n",
    "                              \"review\": [review_text],\n",
    "                              \"score\": [score],\n",
    "                              \"like\": [like],\n",
    "                              \"dislike\": [dislike],\n",
    "                              \"created at\": [created_at],\n",
    "                              \"watch_movie\": [watch_movie and True or False]})\n",
    "        lis_df = pd.concat([lis_df, li_df])\n",
    "    return(lis_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv2019 = pd.read_table(\"~/MovieTrends/data/movie_list_200602.csv\", sep = \",\", encoding = \"EUC-KR\", header=0, names = [\"Title\", \"Subtitle\", \"TitleEn\", \"OpenDate\", \"Count\"])\n",
    "mv2019.OpenDate = pd.Series([pd.Timestamp(datetime.strptime(i, '%Y%m%d')) for i in map(str, mv2019.OpenDate)])\n",
    "mv2019 = mv2019[[\"Title\", \"OpenDate\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "598 | 퍼펙트 스트레인저 | 24 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=66498\n",
      "599 | 퍼펙트 타겟 | 0 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=25134\n",
      "600 | 퍼펙트맨 | 469 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=180390\n",
      "601 | 평일 오후 3시의 연인 | 5 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=159743\n",
      "602 | 포 핸즈 | 1 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=165111\n",
      "603 | 포레스트 헌터스 워 | 0 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=190242\n",
      "604 | 폭설 | 0 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=179305\n",
      "605 | 폴라로이드 | 10 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=162203\n",
      "606 | 프란치스코 교황: 맨 오브 히스 워드 | 15 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=174748\n",
      "607 | 프렌드 존 | 0 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=71580\n",
      "608 | 프렌즈: 둥지탈출 | 4 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=184253\n",
      "609 | 프로디지 | 0 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=161267\n",
      "610 | 프로스펙트 | 0 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=172827\n",
      "611 | 프린스 코기 | 31 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=183122\n",
      "612 | 플레이 오어 다이 | 0 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=183995\n",
      "613 | 플레이모빌: 더 무비 | 5 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=182020\n",
      "614 | 피터팬: 후크 선장과 결투의 날 | 5 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=185479\n",
      "615 | 필그리미지 | 3 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=144965\n",
      "616 | 하나레이 베이 | 3 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=179971\n",
      "617 | 하우스 오브 투모로우 | 2 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=152659\n",
      "618 | 하이 라이프 | 6 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=171455\n",
      "619 | 하트스톤 | 8 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=155041\n",
      "620 | 하트스트링스 | 1 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=158522\n",
      "621 | 한강에게 | 8 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=174292\n",
      "622 | 한낮의 피크닉 | 7 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=184266\n",
      "623 | 할머니의 고양이 그리고 522걸음의 여행 | 0 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=189026\n",
      "624 | 항거: 유관순 이야기 | 723 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=182360\n",
      "625 | 해안가로의 여행 | 0 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=139441\n",
      "626 | 해킹 헌터: 마인드 컨트롤 | 1 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=188320\n",
      "627 | 해피 데스데이 2 유 | 291 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=181411\n",
      "628 | 해피니스 로드 | 0 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=168972\n",
      "629 | 해피엔드 | 5 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=162875\n",
      "630 | 해피타임 스파이 | 8 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=172758\n",
      "631 | 행동하는 양심 김대중 | 60 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=189068\n",
      "632 | 행맨 | 3 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=162296\n",
      "633 | 행복한 라짜로 | 22 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=174833\n",
      "634 | 허비 행콕: 무한한 가능성 | 3 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=49687\n",
      "635 | 허슬러 | 0 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=11004\n",
      "636 | 험악한 꿈 | 3 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=154433\n",
      "637 | 헤드헌터 | 0 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=85946\n",
      "638 | 헤로니모 | 24 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=189054\n",
      "639 | 헬로 몽키 | 1 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=179411\n",
      "640 | 헬로우 평양 | 4 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=185485\n",
      "641 | 헬보이 | 263 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=164200\n",
      "642 | 호크니 | 12 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=133459\n",
      "643 | 호텔 뭄바이 | 148 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=165022\n",
      "644 | 호흡 | 9 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=179310\n",
      "645 | 홍금보의 라이프타임 트레저 | 0 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=189080\n",
      "646 | 후로티로봇 극장판 | 2 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=146381\n",
      "647 | 히치하이크 | 6 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=168740\n",
      "648 | 힘을 내요, 미스터 리 | 578 pages | https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=175316\n"
     ]
    }
   ],
   "source": [
    "movie_reviews_list = []\n",
    "piece_size = 100\n",
    "for piece_idx in range(0, len(mv2019), piece_size):\n",
    "    movie_list = mv2019[\"Title\"][piece_idx:piece_idx+piece_size]\n",
    "    movie_reviews = pd.DataFrame()\n",
    "    for movie_nm in movie_list:\n",
    "        review_url, num_pages = get_review_info(movie_nm)\n",
    "        print(list(mv2019[\"Title\"]).index(movie_nm), \"|\", movie_nm, \"|\", num_pages, \"pages |\", review_url)\n",
    "        movie_review = pd.DataFrame()\n",
    "#         for i in range(1, num_pages+1): # 각 영화 모든 리뷰 수집\n",
    "        for i in range(1, min(num_pages+1, 11)): # 각 영화 리뷰 최대 100개씩 수집\n",
    "#             print(movie_nm + \" | \" + str(i) + \"/\" + str(num_pages))\n",
    "            movie_review_subset = get_movie_review_subset(movie_nm, review_url + '&page=' + str(i))\n",
    "            movie_review = pd.concat([movie_review, movie_review_subset])\n",
    "        movie_reviews = pd.concat([movie_reviews, movie_review])\n",
    "    movie_reviews_list.append(movie_reviews.reset_index().drop(['index'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_review_final = pd.concat(movie_reviews_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_review_final.to_csv(\"~/MovieTrends/output/movie_review_final.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv2019[mv2019[\"Title\"] == \"공포의 묘지\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv2019.iloc[40:45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_nm = '공포의 묘지: 망자의 저주'\n",
    "review_url, num_pages = get_review_info(movie_nm)\n",
    "print(movie_nm, \" | \", num_pages, \"pages | \", review_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_review = pd.DataFrame()\n",
    "for i in range(1, num_pages+1):\n",
    "    #print(movie_nm + \" | \" + str(i) + \"/\" + str(num_pages))\n",
    "    movie_review_subset = get_movie_review_subset(movie_nm, review_url + '&page=' + str(i))\n",
    "    movie_review = pd.concat([movie_review, movie_review_subset])\n",
    "movie_reviews = pd.concat([movie_reviews, movie_review])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = requests.get(url)\n",
    "html = BeautifulSoup(resp.content, 'html.parser')\n",
    "score_result = html.find('div', {'class': 'score_result'})\n",
    "lis = score_result.findAll('li')\n",
    "lis_df = pd.DataFrame()\n",
    "for li in lis:\n",
    "    nickname = li.findAll('a')[0].find('span').getText() if li.findAll('a')[0].find('span') is not None else None\n",
    "    created_at = datetime.strptime(li.find('dt').findAll('em')[-1].getText(), \"%Y.%m.%d %H:%M\")\n",
    "    review_text = li.find('p').getText().translate(str.maketrans({\"\\n\": \"\", \"\\r\": \"\", \"\\t\": \"\"}))\n",
    "    score = li.find('em').getText()\n",
    "    btn_likes = li.find('div', {'class': 'btn_area'}).findAll('strong')\n",
    "    like = btn_likes[0].getText()\n",
    "    dislike = btn_likes[1].getText()\n",
    "    watch_movie = li.find('span', {'class':'ico_viewer'})\n",
    "    \n",
    "    li_df = pd.DataFrame({\"movie_nm\": [movie_nm],\n",
    "                          \"nickname\": [nickname],\n",
    "                          \"review\": [review_text],\n",
    "                          \"score\": [score],\n",
    "                          \"like\": [like],\n",
    "                          \"dislike\": [dislike],\n",
    "                          \"created at\": [created_at],\n",
    "                          \"watch_movie\": [watch_movie and True or False]})\n",
    "    lis_df = pd.concat([lis_df, li_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_movie_review_subset(movie_nm, review_url + '&page=' + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_url + '&page=' + str(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_reviews = pd.concat(movie_review_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_reviews.to_csv(\"~/MovieTrends/output/review_all.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FOR TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_url = \"https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=136990&type=after&page=1\"\n",
    "resp = requests.get(review_url)\n",
    "html = BeautifulSoup(resp.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_result = html.find('div', {'class': 'score_result'})\n",
    "lis = score_result.findAll('li')\n",
    "# lis[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_text = lis[0].find('p').getText()\n",
    "review_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = lis[0].find('em').getText()\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "like = lis[0].find('div', {'class': 'btn_area'}).findAll('span')[1].getText()\n",
    "dislike = lis[0].find('div', {'class': 'btn_area'}).findAll('span')[3].getText()\n",
    "like, dislike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nickname = lis[0].findAll('a')[0].find('span').getText()\n",
    "nickname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_nm = input(\"Enter movie name: \")\n",
    "search_url = \"https://movie.naver.com/movie/search/result.nhn?query=\" + movie_nm + \"&section=all&ie=utf8\"\n",
    "search_resp = requests.get(search_url)\n",
    "search_html = BeautifulSoup(search_resp.content, 'html.parser')\n",
    "a_tag = search_html.find('ul', {'class': 'search_list_1'}).find('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_movie = re.compile('code=[0-9]{6}')\n",
    "movie_code = re.sub('code=', '', re_movie.findall(str(a_tag))[0])\n",
    "review_url = \"https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=\" + movie_code + \"&type=after&page=1\"\n",
    "return(review_url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 (miniconda)",
   "language": "python",
   "name": "python3-mc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
