{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naver Movie Review Crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_code(movie_nm):\n",
    "    movie_code = None\n",
    "\n",
    "    search_url = \"https://movie.naver.com/movie/search/result.nhn?query=\" + movie_nm + \"&section=all&ie=utf8\"\n",
    "    search_resp = requests.get(search_url)\n",
    "    search_html = BeautifulSoup(search_resp.content, 'html.parser')\n",
    "    if search_html.find('ul', {'class': 'search_list_1'}) is not None: # 해당 영화 검색 결과가 존재하는 경우\n",
    "        a_tag = search_html.find('ul', {'class': 'search_list_1'}).find('a')\n",
    "        re_movie = re.compile('code=[0-9]{1,6}')\n",
    "        movie_code = re.sub('code=', '', re_movie.findall(str(a_tag))[0])\n",
    "    return(movie_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_review_info(movie_nm):\n",
    "    review_url, num_pages = None, 0\n",
    "\n",
    "    movie_code = get_movie_code(movie_nm)\n",
    "    if movie_code is not None: # 해당 영화 검색 결과가 존재하는 경우\n",
    "        review_url = \"https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=\" + movie_code\n",
    "        review_html = BeautifulSoup(requests.get(review_url).content, 'html.parser')\n",
    "        review_score = review_html.find('div', {'class': 'score_total'})\n",
    "        if review_score is not None: # 해당 영화 리뷰 페이지가 존재하는 경우 (국내개봉작)\n",
    "            review_count = int(review_score.find('strong').findChildren('em')[-1].getText().replace(',', ''))\n",
    "            num_pages = int(math.ceil(review_count/10))\n",
    "    return(review_url, num_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_review_page(movie_nm, url):\n",
    "    resp = requests.get(url)\n",
    "    html = BeautifulSoup(resp.content, 'html.parser')\n",
    "    score_result = html.find('div', {'class': 'score_result'})\n",
    "    lis = score_result.findAll('li')\n",
    "    review_page = pd.DataFrame()\n",
    "#     for li in [li for li in lis if li.findAll('a') != []]: # filtered review 수집 제외\n",
    "    for li in lis:\n",
    "        nickname = li.find('a').find('span').getText() if (li.find('a') and li.find('a').find('span')) is not None else None\n",
    "        created_at = datetime.strptime(li.find('dt').findAll('em')[-1].getText(), \"%Y.%m.%d %H:%M\") if li.find('dt') is not None else None\n",
    "        review_text = li.find('p').getText().translate(str.maketrans({\"\\n\": \"\", \"\\r\": \"\", \"\\t\": \"\"})) if li.find('p') is not None else None\n",
    "        score = li.find('em').getText() if li.find('em') is not None else None\n",
    "        btn_likes = li.find('div', {'class': 'btn_area'}).findAll('strong') if li.find('div', {'class': 'btn_area'}) is not None else None\n",
    "        like = btn_likes[0].getText() if btn_likes is not None else None\n",
    "        dislike = btn_likes[1].getText() if btn_likes is not None else None\n",
    "        watch_movie = li.find('span', {'class':'ico_viewer'})\n",
    "        review_row = {\"movie_nm\": movie_nm,\n",
    "                      \"nickname\": nickname,\n",
    "                      \"review\": review_text,\n",
    "                      \"score\": score,\n",
    "                      \"like\": like,\n",
    "                      \"dislike\": dislike,\n",
    "                      \"created_at\": created_at,\n",
    "                      \"watch_movie\": watch_movie and True or False}\n",
    "        review_page = review_page.append(review_row, ignore_index = True)\n",
    "    return(review_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(movie_nm):\n",
    "    score = ['', '', '']\n",
    "    \n",
    "    movie_code = get_movie_code(movie_nm)\n",
    "    if movie_code is not None: # 해당 영화 검색 결과가 존재하는 경우\n",
    "        score_url = \"https://movie.naver.com/movie/bi/mi/basic.nhn?code=\" + movie_code\n",
    "        score_resp = requests.get(score_url)\n",
    "        socre_html = BeautifulSoup(score_resp.content, 'html.parser')\n",
    "        score_main = socre_html.find('div', {'class': 'main_score'})\n",
    "        \n",
    "        if score_main is not None:\n",
    "            watcher_tag = score_main.find('a', {'class': 'ntz_score'}).find('div', {'class': 'star_score'}).findAll('em') if score_main.find('a', {'class': 'ntz_score'}) is not None else ''\n",
    "            expert_tag = score_main.find('div', {'class': 'spc_score_area'}).find('div', {'class': 'star_score'}).findAll('em') if score_main.find('div', {'class': 'spc_score_area'}) is not None else ''\n",
    "            netizen_tag = score_main.find('a', {'id': 'pointNetizenPersentWide'}).findAll('em') if score_main.find('a', {'id': 'pointNetizenPersentWide'}) is not None else ''\n",
    "            score = [re.sub('>|<', '', \"\".join([str(i) for i in re.compile('>[0-9, .]<').findall(\"\".join([str(i) for i in tag]))])) for tag in [watcher_tag, expert_tag, netizen_tag]]\n",
    "    return(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def old_get_review_info(movie_nm):\n",
    "    review_url, num_pages = None, 0\n",
    "    search_url = \"https://movie.naver.com/movie/search/result.nhn?query=\" + movie_nm + \"&section=all&ie=utf8\"\n",
    "    search_resp = requests.get(search_url)\n",
    "    search_html = BeautifulSoup(search_resp.content, 'html.parser')\n",
    "    if search_html.find('ul', {'class': 'search_list_1'}) is not None: # 해당 영화 검색 결과가 존재하는 경우\n",
    "        a_tag = search_html.find('ul', {'class': 'search_list_1'}).find('a')\n",
    "        re_movie = re.compile('code=[0-9]{1,6}')\n",
    "        movie_code = re.sub('code=', '', re_movie.findall(str(a_tag))[0])\n",
    "        review_url = \"https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=\" + movie_code\n",
    "        review_html = BeautifulSoup(requests.get(review_url).content, 'html.parser')\n",
    "        review_score = review_html.find('div', {'class': 'score_total'})\n",
    "        if review_score is not None: # 해당 영화 리뷰 페이지가 존재하는 경우 (국내개봉작)\n",
    "            review_count = int(review_score.find('strong').findChildren('em')[-1].getText().replace(',', ''))\n",
    "            num_pages = int(math.ceil(review_count/10))\n",
    "    return(review_url, num_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def old_get_movie_review_subset(movie_nm, url):\n",
    "    resp = requests.get(url)\n",
    "    html = BeautifulSoup(resp.content, 'html.parser')\n",
    "    score_result = html.find('div', {'class': 'score_result'})\n",
    "    lis = score_result.findAll('li')\n",
    "    lis_df = pd.DataFrame()\n",
    "    for li in lis:\n",
    "        nickname = li.findAll('a')[0].find('span').getText() if li.findAll('a')[0].find('span') is not None else None\n",
    "        created_at = datetime.strptime(li.find('dt').findAll('em')[-1].getText(), \"%Y.%m.%d %H:%M\")\n",
    "        review_text = li.find('p').getText().translate(str.maketrans({\"\\n\": \"\", \"\\r\": \"\", \"\\t\": \"\"}))\n",
    "        score = li.find('em').getText()\n",
    "        btn_likes = li.find('div', {'class': 'btn_area'}).findAll('strong')\n",
    "        like = btn_likes[0].getText()\n",
    "        dislike = btn_likes[1].getText()\n",
    "        watch_movie = li.find('span', {'class':'ico_viewer'})\n",
    "        \n",
    "        li_df = pd.DataFrame({\"movie_nm\": [movie_nm],\n",
    "                              \"nickname\": [nickname],\n",
    "                              \"review\": [review_text],\n",
    "                              \"score\": [score],\n",
    "                              \"like\": [like],\n",
    "                              \"dislike\": [dislike],\n",
    "                              \"created at\": [created_at],\n",
    "                              \"watch_movie\": [watch_movie and True or False]})\n",
    "        lis_df = pd.concat([lis_df, li_df])\n",
    "    return(lis_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def old_temp_get_score(movie_nm):\n",
    "    review_url, num_pages = None, 0\n",
    "    search_url = \"https://movie.naver.com/movie/search/result.nhn?query=\" + movie_nm + \"&section=all&ie=utf8\"\n",
    "    search_resp = requests.get(search_url)\n",
    "    search_html = BeautifulSoup(search_resp.content, 'html.parser')\n",
    "    \n",
    "    watcher_score, expert_score, netizen_score = '', '', ''\n",
    "    if search_html.find('ul', {'class': 'search_list_1'}) is not None: # 해당 영화 검색 결과가 존재하는 경우\n",
    "        a_tag = search_html.find('ul', {'class': 'search_list_1'}).find('a')\n",
    "        re_movie = re.compile('code=[0-9]{1,6}')\n",
    "        movie_code = re.sub('code=', '', re_movie.findall(str(a_tag))[0])\n",
    "        #################################################################\n",
    "        score_url = \"https://movie.naver.com/movie/bi/mi/basic.nhn?code=\" + movie_code\n",
    "        resp = requests.get(score_url)\n",
    "        html = BeautifulSoup(resp.content, 'html.parser')\n",
    "        main_score = html.find('div', {'class': 'main_score'})\n",
    "        \n",
    "        if main_score is not None:\n",
    "            score_tag = main_score.findAll('div', {'class': 'star_score'})[0].findAll('em')\n",
    "            watcher_score = re.sub('>|<', '', \"\".join([str(i) for i in re.compile('>[0-9, .]<').findall(\"\".join([str(i) for i in score_tag]))]))\n",
    "            score_tag = main_score.findAll('div', {'class': 'star_score'})[1].findAll('em')\n",
    "            expert_score = re.sub('>|<', '', \"\".join([str(i) for i in re.compile('>[0-9, .]<').findall(\"\".join([str(i) for i in score_tag]))]))\n",
    "            score_tag = main_score.findAll('div', {'class': 'star_score'})[2].findAll('em')\n",
    "            netizen_score = re.sub('>|<', '', \"\".join([str(i) for i in re.compile('>[0-9, .]<').findall(\"\".join([str(i) for i in score_tag]))]))\n",
    "    return(watcher_score, expert_score, netizen_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 (Global)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
